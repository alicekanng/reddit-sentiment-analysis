{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0db9da6c-1e0e-4d85-93fe-12bcd6fa32d5",
   "metadata": {},
   "source": [
    "## Data Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e2a68b94-0901-4e94-9a99-38f9c5e10bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "740b3445-ba8f-48fb-88b3-53e6bc2194b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_data(filename):\n",
    "    data = dict()\n",
    "    with open(filename) as f:\n",
    "        data = json.load(f)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e76e330a-f531-4c8e-8520-be51a49574fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_posts_titles(data):\n",
    "    posts = dict()\n",
    "\n",
    "    for k in data.keys():\n",
    "        state_posts = []\n",
    "        for p in data[k]:\n",
    "            post = {\n",
    "                \"selftext\": p[\"selftext\"],\n",
    "                \"title\": p[\"title\"]\n",
    "            }\n",
    "            state_posts.append(post)\n",
    "        posts[k] = state_posts\n",
    "    return posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "334b21df-1517-4771-8a48-a13a48da18b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_comments(data):\n",
    "    comments = dict()\n",
    "\n",
    "    for k in data.keys():\n",
    "        state = data[k]\n",
    "        state_comments = []\n",
    "        \n",
    "        for p in state.keys():\n",
    "            for c in state[p]:\n",
    "                comment = {\n",
    "                    \"body\": c[\"body\"]\n",
    "                }\n",
    "                state_comments.append(comment)\n",
    "        \n",
    "        comments[k] = state_comments\n",
    "    return comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a7979300-58be-47d0-8799-cb0a89d48bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get raw data for after and before election\n",
    "raw_after_posts = extract_data('data/after_election_posts_data.json')\n",
    "raw_after_comments = extract_data('data/after_election_SAMPLE_comments_data.json')\n",
    "raw_before_posts = extract_data('data/before_election_posts_data.json')\n",
    "raw_before_comments = extract_data('data/before_election_SAMPLE_comments_data.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "28e7cc2d-3ccb-4ade-bbd6-8667d9e8ba58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract just the useful data from both posts and comments\n",
    "after_posts = get_posts_titles(raw_after_posts)\n",
    "before_posts = get_posts_titles(raw_before_posts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "18635263-aadd-4a22-8bd8-9c080066912d",
   "metadata": {},
   "outputs": [],
   "source": [
    "after_comments = get_comments(raw_after_comments)\n",
    "before_comments = get_comments(raw_before_comments)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff0bd0e4-6b30-456d-ad81-e16374bc77bc",
   "metadata": {},
   "source": [
    "## Filter political posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "327ad669-a2d9-4f79-8626-bfb6747649c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of words to look for when filtering political posts\n",
    "keywords = extract_data('data/keywords/keywords.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4c135d63-30bc-4b12-a89b-07779f8af736",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'economy': ['prices',\n",
       "  'inflation',\n",
       "  'triggering',\n",
       "  'stock',\n",
       "  'scores',\n",
       "  'expensive',\n",
       "  'felt',\n",
       "  'rates',\n",
       "  'respondents',\n",
       "  'professional',\n",
       "  'economic',\n",
       "  'stamps',\n",
       "  'repercussions',\n",
       "  'roxanne',\n",
       "  'afloat',\n",
       "  'aquaculture',\n",
       "  'priced',\n",
       "  'manageable',\n",
       "  'succumbing',\n",
       "  'necessities'],\n",
       " 'democracy': ['siphoned',\n",
       "  'mudde',\n",
       "  'legalized',\n",
       "  'hence',\n",
       "  'capitalism',\n",
       "  'rectify',\n",
       "  'columns',\n",
       "  'newest',\n",
       "  'reich',\n",
       "  'acquisitions',\n",
       "  'robertreich',\n",
       "  'stalled',\n",
       "  'nausea',\n",
       "  'misallocation',\n",
       "  'inbox',\n",
       "  'rigs',\n",
       "  'cas',\n",
       "  'eldercare',\n",
       "  'summoned',\n",
       "  'corporations'],\n",
       " 'security': ['social',\n",
       "  'shortfall',\n",
       "  'finances',\n",
       "  'insolvency',\n",
       "  '2031',\n",
       "  'footing',\n",
       "  'mismanage',\n",
       "  'proposing',\n",
       "  'waving',\n",
       "  'trustees',\n",
       "  'insolvent',\n",
       "  'modernize',\n",
       "  'holland',\n",
       "  'ss',\n",
       "  '2033',\n",
       "  'breck',\n",
       "  'dumas',\n",
       "  'angrily',\n",
       "  'buckle',\n",
       "  'oasi'],\n",
       " 'immigration': ['immigrants',\n",
       "  'policies',\n",
       "  'border',\n",
       "  'forgiveness',\n",
       "  'country',\n",
       "  'about',\n",
       "  'sues',\n",
       "  'migrants',\n",
       "  'illegally',\n",
       "  'wanted',\n",
       "  'harris',\n",
       "  'illegal',\n",
       "  'said',\n",
       "  'did',\n",
       "  'from',\n",
       "  'trump',\n",
       "  'on',\n",
       "  'mass',\n",
       "  'for',\n",
       "  'pressed'],\n",
       " 'education': ['pearson',\n",
       "  'indoctrination',\n",
       "  'ferial',\n",
       "  'flopped',\n",
       "  'classrooms',\n",
       "  'oriented',\n",
       "  'devos',\n",
       "  '529',\n",
       "  'greenlight',\n",
       "  'partially',\n",
       "  'betsy',\n",
       "  'futureed',\n",
       "  'subsidize',\n",
       "  'absenteeism',\n",
       "  'sparsely',\n",
       "  'charters',\n",
       "  'schreiner',\n",
       "  'petrilli',\n",
       "  'fordham',\n",
       "  'sidelined'],\n",
       " 'healthcare': ['creators',\n",
       "  'schar',\n",
       "  '1tn',\n",
       "  'outpolls',\n",
       "  'concepts',\n",
       "  'uninsured',\n",
       "  'blowtorch',\n",
       "  'goer',\n",
       "  'obamacare',\n",
       "  'medicaid',\n",
       "  'affordable',\n",
       "  'replacing',\n",
       "  'boot',\n",
       "  'sections',\n",
       "  'ingrained',\n",
       "  'entrepreneurs',\n",
       "  'subsidies',\n",
       "  'incorporated',\n",
       "  'takers',\n",
       "  'empower'],\n",
       " 'abortion': ['roe',\n",
       "  'bans',\n",
       "  'ban',\n",
       "  'wade',\n",
       "  'abortions',\n",
       "  'life',\n",
       "  'incest',\n",
       "  'exceptions',\n",
       "  'procedure',\n",
       "  'restrictions',\n",
       "  'obtain',\n",
       "  'care',\n",
       "  'pregnancy',\n",
       "  'guaranteeing',\n",
       "  'rape',\n",
       "  'unelected',\n",
       "  'votingtim',\n",
       "  'moderates',\n",
       "  'callous',\n",
       "  'allredrepublicans']}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "34504812-a3b7-4bea-9bd1-b8998f2e09ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter some keywords out based on reasoning\n",
    "words_to_remove = {\n",
    "    'economy': [\"triggering\", \"felt\", \"afloat\", \"manageable\", \"succumbing\"],\n",
    "    'democracy': [\"mudde\", \"hence\", \"newest\", \"stalled\", \"nausea\", \"rigs\", \"cas\", \"summoned\"],\n",
    "    'security': [\"footing\", \"proposing\", \"holland\", \"angrily\", \"buckle\"],\n",
    "    'immigration': [\"forgiveness\", \"country\", \"about\", \"wanted\", \"harris\", \"said\", \"did\", \"from\", \"trump\", \"on\", \"for\", \"pressed\", \"mass\"],\n",
    "    'education': [\"ferial\", \"flopped\", \"oriented\", \"greenlight\", \"partially\", \"sparsely\"],\n",
    "    'healthcare': [\"creators\", \"1tn\", \"concepts\", \"blowtorch\", \"replacing\", \"boot\", \"sections\", \"incorporated\", \"takers\", \"empower\"],\n",
    "    'abortion': [\"exceptions\", \"procedure\", \"obtain\", \"care\", \"guaranteeing\", \"moderates\", \"sections\", \"callous\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1df8a869-61e7-424d-bbbb-4836869761aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "words_to_replace = {\n",
    "    'economy': {\n",
    "        'roxanne': 'roxanne persaud'\n",
    "    },\n",
    "    'security': {\n",
    "        'ss': 'ssa'\n",
    "    },\n",
    "    'education': {\n",
    "        'betsy': 'betsy devos'\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d9c2364c-1714-41b7-b2ea-fba5b906bd68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_kws():\n",
    "    filtered_kws = keywords.copy()\n",
    "    \n",
    "    for w in filtered_kws.keys():\n",
    "        filtered = [wd for wd in filtered_kws[w] if wd not in words_to_remove[w]]\n",
    "        filtered_kws[w] = filtered\n",
    "\n",
    "        if w in words_to_replace.keys():\n",
    "            replacement = words_to_replace[w]\n",
    "            og_word = list(replacement.keys())[0]\n",
    "            new_word = replacement[og_word]\n",
    "\n",
    "            filtered_kws[w].remove(og_word)\n",
    "            filtered_kws[w].append(new_word)\n",
    "    return filtered_kws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d40445ee-4f9c-4716-b214-cf2ceb54b0e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'economy': ['prices',\n",
       "  'inflation',\n",
       "  'stock',\n",
       "  'scores',\n",
       "  'expensive',\n",
       "  'rates',\n",
       "  'respondents',\n",
       "  'professional',\n",
       "  'economic',\n",
       "  'stamps',\n",
       "  'repercussions',\n",
       "  'aquaculture',\n",
       "  'priced',\n",
       "  'necessities',\n",
       "  'roxanne persaud'],\n",
       " 'democracy': ['siphoned',\n",
       "  'legalized',\n",
       "  'capitalism',\n",
       "  'rectify',\n",
       "  'columns',\n",
       "  'reich',\n",
       "  'acquisitions',\n",
       "  'robertreich',\n",
       "  'misallocation',\n",
       "  'inbox',\n",
       "  'eldercare',\n",
       "  'corporations'],\n",
       " 'security': ['social',\n",
       "  'shortfall',\n",
       "  'finances',\n",
       "  'insolvency',\n",
       "  '2031',\n",
       "  'mismanage',\n",
       "  'waving',\n",
       "  'trustees',\n",
       "  'insolvent',\n",
       "  'modernize',\n",
       "  '2033',\n",
       "  'breck',\n",
       "  'dumas',\n",
       "  'oasi',\n",
       "  'ssa'],\n",
       " 'immigration': ['immigrants',\n",
       "  'policies',\n",
       "  'border',\n",
       "  'sues',\n",
       "  'migrants',\n",
       "  'illegally',\n",
       "  'illegal'],\n",
       " 'education': ['pearson',\n",
       "  'indoctrination',\n",
       "  'classrooms',\n",
       "  'devos',\n",
       "  '529',\n",
       "  'futureed',\n",
       "  'subsidize',\n",
       "  'absenteeism',\n",
       "  'charters',\n",
       "  'schreiner',\n",
       "  'petrilli',\n",
       "  'fordham',\n",
       "  'sidelined',\n",
       "  'betsy devos'],\n",
       " 'healthcare': ['schar',\n",
       "  'outpolls',\n",
       "  'uninsured',\n",
       "  'goer',\n",
       "  'obamacare',\n",
       "  'medicaid',\n",
       "  'affordable',\n",
       "  'ingrained',\n",
       "  'entrepreneurs',\n",
       "  'subsidies'],\n",
       " 'abortion': ['roe',\n",
       "  'bans',\n",
       "  'ban',\n",
       "  'wade',\n",
       "  'abortions',\n",
       "  'life',\n",
       "  'incest',\n",
       "  'restrictions',\n",
       "  'pregnancy',\n",
       "  'rape',\n",
       "  'unelected',\n",
       "  'votingtim',\n",
       "  'allredrepublicans']}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_kws = filter_kws()\n",
    "filtered_kws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1fdb8311-f9e8-4ec2-9389-cb1e1ae5472a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# group filtered political posts \n",
    "def group_political_posts(posts):\n",
    "    grouped_posts = dict()\n",
    "        \n",
    "    for k in posts.keys():\n",
    "        grouped_posts[k] = dict()\n",
    "        state_posts = posts[k]\n",
    "\n",
    "        for topic in filtered_kws.keys():\n",
    "            post_set = set()\n",
    "            \n",
    "            for post in state_posts:\n",
    "                for word in filtered_kws[topic]:\n",
    "                    if word in post[\"selftext\"].lower() or word in post[\"title\"].lower():\n",
    "                        post_set.add(post[\"selftext\"] + \" \" + post[\"title\"])\n",
    "                grouped_posts[k][topic] = list(post_set)\n",
    "    return grouped_posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d2978a6d-b76a-4b95-bd48-c17c314ba066",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_posts_after = group_political_posts(after_posts)\n",
    "grouped_posts_before = group_political_posts(before_posts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b94c87d6-73f3-4242-b490-9191a6407bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# group filtered political comments \n",
    "def group_political_comments(comments):\n",
    "    grouped_comments = dict()\n",
    "        \n",
    "    for k in comments.keys():\n",
    "        grouped_comments[k] = dict()\n",
    "        state_comments = comments[k]\n",
    "\n",
    "        for topic in filtered_kws.keys():\n",
    "            comment_set = set()\n",
    "                \n",
    "            for comment in state_comments:\n",
    "                for word in filtered_kws[topic]:\n",
    "                    if word in comment[\"body\"].lower():\n",
    "                        comment_set.add(comment[\"body\"])\n",
    "                grouped_comments[k][topic] = list(comment_set)\n",
    "    return grouped_comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "08829e29-0b83-4f7d-89f5-f7b4dcdbeac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_comments_after = group_political_comments(after_comments)\n",
    "grouped_comments_before = group_political_comments(before_comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "051772ac-16e1-4fe7-87ea-4e9ddf163f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print out size of grouped posts per state - for testing\n",
    "def count_grouped_posts(grouped_posts):\n",
    "    group_posts_size = dict()\n",
    "    for k in grouped_posts.keys():\n",
    "        group_posts_size[k] = dict()\n",
    "        \n",
    "        for t in grouped_posts[k].keys(): \n",
    "            group_posts_size[k][t] = len(grouped_posts[k][t])\n",
    "    return group_posts_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3197339a-245e-444e-9fbf-4b77155f88e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'california': {'economy': 5,\n",
       "  'democracy': 0,\n",
       "  'security': 1,\n",
       "  'immigration': 5,\n",
       "  'education': 0,\n",
       "  'healthcare': 0,\n",
       "  'abortion': 6},\n",
       " 'michigan': {'economy': 11,\n",
       "  'democracy': 0,\n",
       "  'security': 16,\n",
       "  'immigration': 10,\n",
       "  'education': 3,\n",
       "  'healthcare': 2,\n",
       "  'abortion': 18},\n",
       " 'colorado': {'economy': 2,\n",
       "  'democracy': 0,\n",
       "  'security': 4,\n",
       "  'immigration': 1,\n",
       "  'education': 0,\n",
       "  'healthcare': 0,\n",
       "  'abortion': 4},\n",
       " 'oregon': {'economy': 12,\n",
       "  'democracy': 1,\n",
       "  'security': 8,\n",
       "  'immigration': 16,\n",
       "  'education': 0,\n",
       "  'healthcare': 0,\n",
       "  'abortion': 23},\n",
       " 'hawaii': {'economy': 10,\n",
       "  'democracy': 0,\n",
       "  'security': 5,\n",
       "  'immigration': 8,\n",
       "  'education': 0,\n",
       "  'healthcare': 6,\n",
       "  'abortion': 19},\n",
       " 'oklahoma': {'economy': 3,\n",
       "  'democracy': 0,\n",
       "  'security': 7,\n",
       "  'immigration': 7,\n",
       "  'education': 2,\n",
       "  'healthcare': 1,\n",
       "  'abortion': 12},\n",
       " 'maryland': {'economy': 14,\n",
       "  'democracy': 0,\n",
       "  'security': 14,\n",
       "  'immigration': 11,\n",
       "  'education': 1,\n",
       "  'healthcare': 6,\n",
       "  'abortion': 31},\n",
       " 'arizona': {'economy': 3,\n",
       "  'democracy': 0,\n",
       "  'security': 2,\n",
       "  'immigration': 4,\n",
       "  'education': 0,\n",
       "  'healthcare': 1,\n",
       "  'abortion': 6},\n",
       " 'virginia': {'economy': 13,\n",
       "  'democracy': 0,\n",
       "  'security': 18,\n",
       "  'immigration': 8,\n",
       "  'education': 2,\n",
       "  'healthcare': 7,\n",
       "  'abortion': 30},\n",
       " 'maine': {'economy': 11,\n",
       "  'democracy': 0,\n",
       "  'security': 18,\n",
       "  'immigration': 14,\n",
       "  'education': 0,\n",
       "  'healthcare': 3,\n",
       "  'abortion': 45},\n",
       " 'indiana': {'economy': 9,\n",
       "  'democracy': 1,\n",
       "  'security': 22,\n",
       "  'immigration': 14,\n",
       "  'education': 0,\n",
       "  'healthcare': 3,\n",
       "  'abortion': 35},\n",
       " 'iowa': {'economy': 10,\n",
       "  'democracy': 1,\n",
       "  'security': 8,\n",
       "  'immigration': 8,\n",
       "  'education': 2,\n",
       "  'healthcare': 3,\n",
       "  'abortion': 20},\n",
       " 'washington': {'economy': 9,\n",
       "  'democracy': 2,\n",
       "  'security': 10,\n",
       "  'immigration': 16,\n",
       "  'education': 1,\n",
       "  'healthcare': 4,\n",
       "  'abortion': 17},\n",
       " 'newhampshire': {'economy': 17,\n",
       "  'democracy': 1,\n",
       "  'security': 22,\n",
       "  'immigration': 11,\n",
       "  'education': 0,\n",
       "  'healthcare': 4,\n",
       "  'abortion': 22},\n",
       " 'alaska': {'economy': 7,\n",
       "  'democracy': 1,\n",
       "  'security': 5,\n",
       "  'immigration': 7,\n",
       "  'education': 2,\n",
       "  'healthcare': 2,\n",
       "  'abortion': 23},\n",
       " 'louisiana': {'economy': 12,\n",
       "  'democracy': 0,\n",
       "  'security': 18,\n",
       "  'immigration': 3,\n",
       "  'education': 0,\n",
       "  'healthcare': 1,\n",
       "  'abortion': 15},\n",
       " 'vermont': {'economy': 23,\n",
       "  'democracy': 0,\n",
       "  'security': 13,\n",
       "  'immigration': 16,\n",
       "  'education': 1,\n",
       "  'healthcare': 5,\n",
       "  'abortion': 36},\n",
       " 'newyork': {'economy': 0,\n",
       "  'democracy': 0,\n",
       "  'security': 1,\n",
       "  'immigration': 0,\n",
       "  'education': 0,\n",
       "  'healthcare': 0,\n",
       "  'abortion': 2},\n",
       " 'arkansas': {'economy': 1,\n",
       "  'democracy': 0,\n",
       "  'security': 4,\n",
       "  'immigration': 1,\n",
       "  'education': 0,\n",
       "  'healthcare': 0,\n",
       "  'abortion': 8},\n",
       " 'alabama': {'economy': 3,\n",
       "  'democracy': 0,\n",
       "  'security': 0,\n",
       "  'immigration': 3,\n",
       "  'education': 0,\n",
       "  'healthcare': 0,\n",
       "  'abortion': 5},\n",
       " 'kentucky': {'economy': 4,\n",
       "  'democracy': 0,\n",
       "  'security': 2,\n",
       "  'immigration': 4,\n",
       "  'education': 0,\n",
       "  'healthcare': 0,\n",
       "  'abortion': 8},\n",
       " 'southcarolina': {'economy': 4,\n",
       "  'democracy': 1,\n",
       "  'security': 6,\n",
       "  'immigration': 5,\n",
       "  'education': 0,\n",
       "  'healthcare': 1,\n",
       "  'abortion': 14},\n",
       " 'georgia': {'economy': 15,\n",
       "  'democracy': 1,\n",
       "  'security': 17,\n",
       "  'immigration': 15,\n",
       "  'education': 0,\n",
       "  'healthcare': 7,\n",
       "  'abortion': 32},\n",
       " 'montana': {'economy': 3,\n",
       "  'democracy': 0,\n",
       "  'security': 3,\n",
       "  'immigration': 3,\n",
       "  'education': 0,\n",
       "  'healthcare': 1,\n",
       "  'abortion': 7},\n",
       " 'delaware': {'economy': 5,\n",
       "  'democracy': 1,\n",
       "  'security': 12,\n",
       "  'immigration': 7,\n",
       "  'education': 0,\n",
       "  'healthcare': 2,\n",
       "  'abortion': 20},\n",
       " 'utah': {'economy': 11,\n",
       "  'democracy': 0,\n",
       "  'security': 13,\n",
       "  'immigration': 15,\n",
       "  'education': 2,\n",
       "  'healthcare': 3,\n",
       "  'abortion': 27},\n",
       " 'rhodeisland': {'economy': 22,\n",
       "  'democracy': 1,\n",
       "  'security': 25,\n",
       "  'immigration': 7,\n",
       "  'education': 0,\n",
       "  'healthcare': 10,\n",
       "  'abortion': 25},\n",
       " 'missouri': {'economy': 20,\n",
       "  'democracy': 5,\n",
       "  'security': 15,\n",
       "  'immigration': 21,\n",
       "  'education': 3,\n",
       "  'healthcare': 7,\n",
       "  'abortion': 35},\n",
       " 'tennessee': {'economy': 1,\n",
       "  'democracy': 0,\n",
       "  'security': 0,\n",
       "  'immigration': 2,\n",
       "  'education': 0,\n",
       "  'healthcare': 0,\n",
       "  'abortion': 4},\n",
       " 'nebraska': {'economy': 2,\n",
       "  'democracy': 1,\n",
       "  'security': 8,\n",
       "  'immigration': 5,\n",
       "  'education': 0,\n",
       "  'healthcare': 0,\n",
       "  'abortion': 7},\n",
       " 'illinois': {'economy': 4,\n",
       "  'democracy': 0,\n",
       "  'security': 8,\n",
       "  'immigration': 10,\n",
       "  'education': 0,\n",
       "  'healthcare': 7,\n",
       "  'abortion': 19},\n",
       " 'westvirginia': {'economy': 9,\n",
       "  'democracy': 0,\n",
       "  'security': 8,\n",
       "  'immigration': 4,\n",
       "  'education': 0,\n",
       "  'healthcare': 1,\n",
       "  'abortion': 17},\n",
       " 'newmexico': {'economy': 5,\n",
       "  'democracy': 0,\n",
       "  'security': 6,\n",
       "  'immigration': 7,\n",
       "  'education': 0,\n",
       "  'healthcare': 2,\n",
       "  'abortion': 14},\n",
       " 'mississippi': {'economy': 4,\n",
       "  'democracy': 0,\n",
       "  'security': 5,\n",
       "  'immigration': 3,\n",
       "  'education': 1,\n",
       "  'healthcare': 2,\n",
       "  'abortion': 15},\n",
       " 'kansas': {'economy': 3,\n",
       "  'democracy': 0,\n",
       "  'security': 5,\n",
       "  'immigration': 4,\n",
       "  'education': 0,\n",
       "  'healthcare': 0,\n",
       "  'abortion': 13},\n",
       " 'northdakota': {'economy': 1,\n",
       "  'democracy': 1,\n",
       "  'security': 1,\n",
       "  'immigration': 1,\n",
       "  'education': 0,\n",
       "  'healthcare': 1,\n",
       "  'abortion': 5},\n",
       " 'idaho': {'economy': 2,\n",
       "  'democracy': 1,\n",
       "  'security': 8,\n",
       "  'immigration': 8,\n",
       "  'education': 1,\n",
       "  'healthcare': 1,\n",
       "  'abortion': 16},\n",
       " 'southdakota': {'economy': 3,\n",
       "  'democracy': 1,\n",
       "  'security': 3,\n",
       "  'immigration': 1,\n",
       "  'education': 0,\n",
       "  'healthcare': 1,\n",
       "  'abortion': 3},\n",
       " 'wyoming': {'economy': 4,\n",
       "  'democracy': 0,\n",
       "  'security': 5,\n",
       "  'immigration': 1,\n",
       "  'education': 0,\n",
       "  'healthcare': 1,\n",
       "  'abortion': 10},\n",
       " 'nevada': {'economy': 3,\n",
       "  'democracy': 0,\n",
       "  'security': 3,\n",
       "  'immigration': 0,\n",
       "  'education': 0,\n",
       "  'healthcare': 0,\n",
       "  'abortion': 6}}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_grouped_posts(grouped_posts_after)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "393b3025-6d26-4c90-9be3-74889ddb2e1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'nevada': {'economy': 87,\n",
       "  'democracy': 5,\n",
       "  'security': 54,\n",
       "  'immigration': 84,\n",
       "  'education': 2,\n",
       "  'healthcare': 11,\n",
       "  'abortion': 116},\n",
       " 'wyoming': {'economy': 86,\n",
       "  'democracy': 2,\n",
       "  'security': 54,\n",
       "  'immigration': 53,\n",
       "  'education': 3,\n",
       "  'healthcare': 18,\n",
       "  'abortion': 240}}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_grouped_posts(grouped_comments_after)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be49a20e-90fd-478b-af15-b0736b9d79eb",
   "metadata": {},
   "source": [
    "## Filter posts by candidate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a1c6c97-5a92-47d7-90ce-128c3f57456a",
   "metadata": {},
   "outputs": [],
   "source": [
    "candidate_keywords = {\n",
    "    \"trump\": [\"trump\", \"donald\", \"donald trump\", \"republican\"],\n",
    "    \"harris\": [\"harris\", \"kamala\", \"kamala harris\", \"democrat\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eb88c1c-b4f0-4698-8444-16bed735b377",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter for candidate posts\n",
    "def filter_candidate_posts(all_posts):\n",
    "    candidate_posts = dict()\n",
    "    \n",
    "    for k in all_posts.keys():\n",
    "        candidate_posts[k] = dict()\n",
    "        \n",
    "        for candidate in candidate_keywords.keys():\n",
    "            for w in candidate_keywords[candidate]:\n",
    "                posts = set()\n",
    "                \n",
    "                for post in all_posts[k]:\n",
    "                    if w in post[\"selftext\"].lower() or w in post[\"title\"].lower():\n",
    "                        posts.add(post[\"selftext\"] + \" \" + post[\"title\"])\n",
    "        \n",
    "            candidate_posts[k][candidate] = list(posts)\n",
    "    return candidate_posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "879e74f9-78eb-4f46-833b-c7d1945b621c",
   "metadata": {},
   "outputs": [],
   "source": [
    "after_candidate_posts = filter_candidate_posts(after_posts)\n",
    "before_candidate_posts = filter_candidate_posts(before_posts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4dd9be5-f29d-4dce-98d3-c4ba9900f714",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print out size of political posts per state - for testing\n",
    "def count_candidate_posts(candidate_posts):\n",
    "    can_posts_size = dict()\n",
    "    for k in candidate_posts.keys():\n",
    "        can_posts_size[k] = dict()\n",
    "        for candidate in candidate_keywords.keys():\n",
    "            can_posts_size[k][candidate] = len(candidate_posts[k][candidate])\n",
    "    return can_posts_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85352359-2d9b-4061-ab22-0f431ffe10e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_candidate_posts(after_candidate_posts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07d362a2-2385-4173-be0b-f61bcee45e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_candidate_posts(before_candidate_posts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85277140-2603-468d-a8b0-dc68c6a3bb80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter for candidate comments\n",
    "def filter_candidate_comments(all_comments):\n",
    "    candidate_comments = dict()\n",
    "    \n",
    "    for k in all_comments.keys():\n",
    "        candidate_comments[k] = dict()\n",
    "        \n",
    "        for candidate in candidate_keywords.keys():\n",
    "            for w in candidate_keywords[candidate]:\n",
    "                comments = set()\n",
    "                \n",
    "                for post in all_comments[k]:\n",
    "                    if w in post[\"body\"].lower():\n",
    "                        comments.add(post[\"body\"])\n",
    "        \n",
    "            candidate_comments[k][candidate] = list(comments)\n",
    "    return candidate_comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "538d35dd-1812-45e2-95ed-e5cb0e78a1d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "after_candidate_comments = filter_candidate_comments(after_comments)\n",
    "before_candidate_comments = filter_candidate_comments(before_comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98b4238d-a76a-49d7-aa44-5a12769fd283",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_candidate_posts(after_candidate_comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19845c76-493d-411c-912c-8566a4fc3b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_candidate_posts(before_candidate_comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42ecbf37-cfaf-4dd8-a2e5-6b4e685ad14b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA FORMAT\n",
    "# <after/before>_political_posts contains posts that contain at least one of our defined keywords,\n",
    "# after or before the election respectively.\n",
    "\n",
    "# <after/before>_political_posts = {\n",
    "#    'texas': [\n",
    "#        {\n",
    "#            'selftext': \"__\",\n",
    "#            'title': \"__\"\n",
    "#        },\n",
    "#        {\n",
    "#            'selftext': \"__\",\n",
    "#            'title': \"__\"}\n",
    "#        ...\n",
    "#    ],\n",
    "#    'california': [\n",
    "#        {\n",
    "#            'selftext': \"__\",\n",
    "#            'title': \"__\"\n",
    "#        },\n",
    "#        ...\n",
    "#    ]\n",
    "# }\n",
    "\n",
    "# <after/before>_political_comments contains comments that contain at least one of our defined keywords,\n",
    "# after or before the election respectively.\n",
    "\n",
    "# <after/before>_political_posts = {\n",
    "#    'texas': [\n",
    "#        {\n",
    "#            'body': \"__\"\n",
    "#        },\n",
    "#        {\n",
    "#            'body': \"__\"\n",
    "#        },\n",
    "#        ...\n",
    "#    ],\n",
    "#    'california': [\n",
    "#        {\n",
    "#            'body': \"__\"\n",
    "#        },\n",
    "#        ...\n",
    "#    ]\n",
    "# }\n",
    "\n",
    "# <after/before>_candidate_<posts/comments> contains posts/comments that contain words about each candidate (as defined in candidate_keywords),\n",
    "# after or before the election respectively.\n",
    "\n",
    "# <after/before>_candidate_<posts/comments> = {\n",
    "#    'texas': {\n",
    "#        'trump': [__, __],\n",
    "#        'harris': [__, __],\n",
    "#    },\n",
    "#    'california': {\n",
    "#        'trump': [__, __],\n",
    "#        'harris': [__, __],\n",
    "#    },\n",
    "#    ...\n",
    "# }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d2d5f20-cdc2-4cbb-b312-4eea5114f19f",
   "metadata": {},
   "source": [
    "## Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ff077ff7-79a8-4681-9b0a-cb735a3af526",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sentiment analysis\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "from transformers import TFAutoModelForSequenceClassification\n",
    "from transformers import AutoTokenizer, AutoConfig\n",
    "import numpy as np\n",
    "from scipy.special import softmax\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8fafc40-1503-4031-afe8-d3e271c9c7b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = \"cardiffnlp/twitter-roberta-base-sentiment-latest\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
    "config = AutoConfig.from_pretrained(MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd4650f-9c5e-433d-b03f-873881a2a663",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49c162ce-7ec9-4ecb-aef7-19846892f7de",
   "metadata": {},
   "outputs": [],
   "source": [
    "## TEST - must use PyTorch version, the tensorflow one is not as accurate\n",
    "text = \"I love you!\"\n",
    "encoded_input = tokenizer(text, return_tensors='pt')\n",
    "output = model(**encoded_input)\n",
    "\n",
    "scores = output[0][0].detach().numpy()\n",
    "scores = softmax(scores)\n",
    "\n",
    "ranking = np.argsort(scores)\n",
    "ranking = ranking[::-1]\n",
    "print(ranking)\n",
    "print(config.id2label)\n",
    "\n",
    "for i in range(scores.shape[0]):\n",
    "    l = config.id2label[ranking[i]]\n",
    "    s = scores[ranking[i]]\n",
    "    print(f\"{i+1}) {l} {np.round(float(s), 4)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e0fb060-1896-49d3-8c73-2b45c51b8313",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute highest sentiment score and label for given text\n",
    "def get_sentiment_label_score(text):\n",
    "    # get output from model\n",
    "    encoded_input = tokenizer(text, return_tensors='pt', max_length=512, truncation=True)\n",
    "    output = model(**encoded_input)\n",
    "\n",
    "    # compute softmax scores\n",
    "    scores = output[0][0].detach().numpy()\n",
    "    scores = softmax(scores)\n",
    "\n",
    "    # ranking = list of labels in decreasing order of sentiment score\n",
    "    ranking = np.argsort(scores)[::-1]\n",
    "\n",
    "    # return dictionary of {ranking: score} for given text\n",
    "    # sentiment_map = dict()\n",
    "    # for i in range(scores.shape[0]):\n",
    "    #     l = config.id2label[ranking[i]]\n",
    "    #     s = scores[ranking[i]]\n",
    "    #     sentiment_map[l] = s\n",
    "\n",
    "    # return largest score and the associated sentiment\n",
    "    l = config.id2label[ranking[0]]\n",
    "    s = scores[ranking[0]]\n",
    "    return l, s"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7afc9bdc-392d-4246-9e5c-c33648cd6cae",
   "metadata": {},
   "source": [
    "## Take sentiment score for each candidate\n",
    "\n",
    "Get sentiment score for each sentiment. Might look like:\n",
    "```\n",
    "'texas': {\n",
    "    'trump': {\n",
    "        'positive': {\n",
    "           'scores': [0, 0, ...],\n",
    "           'average': 0.0,\n",
    "           'max': 0.0,\n",
    "           'min': 0.0,\n",
    "           'num_posts': 0\n",
    "       },\n",
    "       'neutral': {\n",
    "           'scores': [0, 0, ...],\n",
    "           'average': 0.0,\n",
    "           'max': 0.0,\n",
    "           'min': 0.0,\n",
    "           'num_posts': 0\n",
    "       }\n",
    "       'negative': {\n",
    "           'scores': [0, 0, ...],\n",
    "           'average': 0.0,\n",
    "           'max': 0.0,\n",
    "           'min': 0.0,\n",
    "           'num_posts': 0\n",
    "       },\n",
    "       'sentiment': 'positive',\n",
    "       'avg_sentiment': 0.0\n",
    "    },\n",
    "    'harris': {\n",
    "        'positive': {\n",
    "            ...\n",
    "       },\n",
    "       'neutral': {\n",
    "           ...\n",
    "       }\n",
    "       'negative': {\n",
    "           ...\n",
    "       },\n",
    "       'sentiment': 'positive',\n",
    "       'avg_sentiment': 0.0\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "99c9d7f0-506d-4ac7-9661-bde0772d19f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper for creating the json above\n",
    "def record_sentiment(sent_data, score):\n",
    "    if \"scores\" in sent_data.keys():\n",
    "        sent_data[\"scores\"].append(score)\n",
    "    else:\n",
    "        sent_data[\"scores\"] = [score]\n",
    "\n",
    "    if \"num_posts\" in sent_data.keys():\n",
    "        sent_data[\"num_posts\"] += 1\n",
    "    else:\n",
    "        sent_data[\"num_posts\"] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37daf9af-2d5a-4b6b-82e7-7f783a2906bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentiment_scores_grouped_posts(grouped_posts):\n",
    "    all_sentiment = dict()\n",
    "    \n",
    "    for k in grouped_posts.keys():\n",
    "        all_sentiment[k] = dict()\n",
    "        \n",
    "        for candidate in grouped_posts[k].keys():\n",
    "            all_sentiment[k][candidate] = dict()\n",
    "            candidate_data = {\n",
    "                'positive': {},\n",
    "                'neutral': {},\n",
    "                'negative': {},\n",
    "            }\n",
    "\n",
    "            for post in grouped_posts[k][candidate]:\n",
    "                label, score = get_sentiment_label_score(post)\n",
    "                record_sentiment(candidate_data[label], score)\n",
    "                \n",
    "                all_sentiment[k][candidate] = candidate_data\n",
    "    return all_sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "782c98ba-95c7-4e3f-b408-1c333dfc1f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# after_cand_sentiments = get_sentiment_scores_grouped_posts(after_candidate_posts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30251b44-e39f-401d-9547-c33b0d4e2bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# before_cand_sentiments = get_sentiment_scores_grouped_posts(before_candidate_posts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0869024-44d2-441f-b581-0f1ec4d68000",
   "metadata": {},
   "outputs": [],
   "source": [
    "# after_cand_comment_sentiments = get_sentiment_scores_grouped_posts(after_candidate_comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "406779d3-37a5-43c0-855f-ed4e008c4fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# before_cand_comment_sentiments = get_sentiment_scores_grouped_posts(before_candidate_comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "5e30f0f2-0225-4164-a08e-72321368d00b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class to make numpy types JSON serializable\n",
    "class NumpyEncoder(json.JSONEncoder):\n",
    "    \"\"\" Special json encoder for numpy types \"\"\"\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, np.integer):\n",
    "            return int(obj)\n",
    "        elif isinstance(obj, np.floating):\n",
    "            return float(obj)\n",
    "        elif isinstance(obj, np.ndarray):\n",
    "            return obj.tolist()\n",
    "        return json.JSONEncoder.default(self, obj)\n",
    "\n",
    "def save_data(filename, data):\n",
    "    with open(filename, 'w') as f:\n",
    "        json.dump(data, f, cls=NumpyEncoder, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adb6f102-0607-4cb5-ba73-2c6d9b8f0fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_data('after_cand_post_sentiments.json', after_cand_sentiments)\n",
    "# save_data('before_cand_post_sentiments.json', before_cand_sentiments)\n",
    "# save_data('after_cand_comment_sentiments.json', after_cand_comment_sentiments)\n",
    "# save_data('before_cand_comment_sentiments.json', before_cand_comment_sentiments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a928ce51-0eac-418f-a970-58acfabbfe96",
   "metadata": {},
   "outputs": [],
   "source": [
    "after_cand_sentiments = extract_data('after_cand_post_sentiments.json')\n",
    "before_cand_sentiments = extract_data('before_cand_post_sentiments.json')\n",
    "after_cand_comment_sentiments = extract_data('after_cand_comment_sentiments.json')\n",
    "before_cand_comment_sentiments = extract_data('before_cand_comment_sentiments.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff0eb0da-e8dd-444e-bdd7-a928870d0f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get average, min, max, and dominant sentiment for each state\n",
    "def get_sentiment_stats(all_sentiment):\n",
    "    stats = all_sentiment.copy()\n",
    "    \n",
    "    for k in stats.keys():\n",
    "        state_sent = stats[k].copy()\n",
    "        \n",
    "        for c in state_sent.keys():\n",
    "            avgs = dict()\n",
    "            candidate = state_sent[c].copy()\n",
    "\n",
    "            for s in candidate.keys():\n",
    "                sent = candidate[s].copy()\n",
    "                if 'scores' not in sent.keys():\n",
    "                    sent['scores'] = [0]\n",
    "                    \n",
    "                sent['min'] = min(sent['scores'])\n",
    "                sent['max'] = max(sent['scores'])\n",
    "                sent['average'] = np.mean(sent['scores'])\n",
    "                avgs[sent['average']] = s\n",
    "                \n",
    "                if 'num_posts' not in sent.keys():\n",
    "                    sent['num_posts'] = 0\n",
    "                candidate[s] = sent\n",
    "            \n",
    "            if len(avgs.keys()) > 0:\n",
    "                avg_sentiment = max(avgs.keys())\n",
    "                sentiment = avgs[avg_sentiment]\n",
    "                candidate['avg_sentiment'] = avg_sentiment\n",
    "                candidate['sentiment'] = sentiment\n",
    "                state_sent[c] = candidate\n",
    "        stats[k] = state_sent\n",
    "    return stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0f7248c-d9b7-4c2a-88b5-9da80848f972",
   "metadata": {},
   "outputs": [],
   "source": [
    "after_cand_stats = get_sentiment_stats(after_cand_sentiments)\n",
    "before_cand_stats = get_sentiment_stats(before_cand_sentiments)\n",
    "after_cand_comment_stats = get_sentiment_stats(after_cand_comment_sentiments)\n",
    "before_cand_comment_stats = get_sentiment_stats(before_cand_comment_sentiments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9db17ccc-e8f7-4265-9298-a880ad4c9f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_data('data/candidate_sentiments/after_cand_post_sentiments.json', after_cand_stats)\n",
    "save_data('data/candidate_sentiments/before_cand_post_sentiments.json', before_cand_stats)\n",
    "save_data('data/candidate_sentiments/after_cand_comment_sentiments.json', after_cand_comment_stats)\n",
    "save_data('data/candidate_sentiments/before_cand_comment_sentiments.json', before_cand_comment_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9528fde-e116-43bc-b99a-91be5f02734c",
   "metadata": {},
   "source": [
    "## Political Direction Analysis\n",
    "Get political direction for each topic. Might look like:\n",
    "```\n",
    "'texas': {\n",
    "    'election': {\n",
    "        'left': {\n",
    "           'scores': [0, 0, ...],\n",
    "           'average': 0.0,\n",
    "           'max': 0.0,\n",
    "           'min': 0.0,\n",
    "           'num_posts': 0\n",
    "       },\n",
    "       'center': {\n",
    "           'scores': [0, 0, ...],\n",
    "           'average': 0.0,\n",
    "           'max': 0.0,\n",
    "           'min': 0.0,\n",
    "           'num_posts': 0\n",
    "       }\n",
    "       'right': {\n",
    "           'scores': [0, 0, ...],\n",
    "           'average': 0.0,\n",
    "           'max': 0.0,\n",
    "           'min': 0.0,\n",
    "           'num_posts': 0\n",
    "       },\n",
    "       'direction': 'left/center/right',\n",
    "       'avg_score': 0.0\n",
    "    },\n",
    "    'abortion': {\n",
    "        'left': {\n",
    "            ...\n",
    "       },\n",
    "       'center': {\n",
    "            ...\n",
    "       }\n",
    "       'right': {\n",
    "            ...\n",
    "       },\n",
    "       'direction': 'left/center/right',\n",
    "       'avg_score': 0.0\n",
    "    ...\n",
    "},\n",
    "'california': {\n",
    "    'election': {\n",
    "        ...\n",
    "    },\n",
    "    ...\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1061ea36-1680-4609-96ff-54aa17b941bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-30 18:00:12.812453: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "pol_dir_tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")\n",
    "pol_dir_model = AutoModelForSequenceClassification.from_pretrained(\"bucketresearch/politicalBiasBERT\")\n",
    "dir_map = {\n",
    "    0: 'left',\n",
    "    1: 'center',\n",
    "    2: 'right'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "649770d1-b28f-4931-984a-d61d4a5e98a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.24744857847690582, 0.17667832970619202, 0.5758731365203857]\n"
     ]
    }
   ],
   "source": [
    "# TEST\n",
    "text = \"I don't believe in climate change\"\n",
    "inputs = pol_dir_tokenizer(text, return_tensors=\"pt\")\n",
    "labels = torch.tensor([0])\n",
    "outputs = pol_dir_model(**inputs, labels=labels)\n",
    "loss, logits = outputs[:2]\n",
    "print(logits.softmax(dim=-1)[0].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6f884e9d-7c5f-4e03-b5e9-425c2bd5e3ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute highest direction score and label for given text\n",
    "def get_direction_label_score(text):\n",
    "    inputs = pol_dir_tokenizer(text, return_tensors=\"pt\", max_length=512, truncation=True)\n",
    "    labels = torch.tensor([0])\n",
    "    outputs = pol_dir_model(**inputs, labels=labels)\n",
    "    loss, logits = outputs[:2]\n",
    "\n",
    "    # ranking = list of labels in decreasing order of direction score\n",
    "    scores = logits.softmax(dim=-1)[0].tolist()\n",
    "    ranking = np.argsort(logits.softmax(dim=-1)[0].tolist())[::-1]\n",
    "\n",
    "    # return largest score and the associated sentiment\n",
    "    l = dir_map[ranking[0]]\n",
    "    s = scores[ranking[0]]\n",
    "    return l, s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b3085052-3fb7-4baa-ad21-51d65c6760ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('left', 0.4164985120296478)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#TEST\n",
    "get_direction_label_score(\"trans lives matter\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1d12dbf5-4bff-4045-b484-4a926419848a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_direction_scores_grouped_posts(grouped_posts):\n",
    "    all_directions = dict()\n",
    "    \n",
    "    for k in grouped_posts.keys():\n",
    "        all_directions[k] = dict()\n",
    "        \n",
    "        for topic in grouped_posts[k].keys():\n",
    "            all_directions[k][topic] = dict()\n",
    "            topic_data = {\n",
    "                'left': {},\n",
    "                'center': {},\n",
    "                'right': {},\n",
    "            }\n",
    "\n",
    "            for post in grouped_posts[k][topic]:\n",
    "                direction, score = get_direction_label_score(post)\n",
    "                record_sentiment(topic_data[direction], score)\n",
    "                \n",
    "                all_directions[k][topic] = topic_data\n",
    "    return all_directions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "13894199-4a4a-461c-9ed9-c77f81876197",
   "metadata": {},
   "outputs": [],
   "source": [
    "after_cand_post_dir = get_direction_scores_grouped_posts(grouped_posts_after)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8beb5ed6-1618-4ef6-bd53-77b96b737386",
   "metadata": {},
   "outputs": [],
   "source": [
    "# before_cand_post_dir = get_direction_scores_grouped_posts(grouped_posts_before)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "6b2d4fe5-e9c4-4d4f-9000-57318f904b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "after_cand_comment_dir = get_direction_scores_grouped_posts(grouped_comments_after)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "308fb795-0fd6-4afd-adf3-6e3f81efdb8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# before_cand_comment_dir = get_direction_scores_grouped_posts(grouped_comments_before)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "8c5b8cff-f9b5-4a0d-bff2-5a8835e4f275",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_data('data/topic_pol_directions/after_cand_post_directions.json', after_cand_post_dir)\n",
    "save_data('data/topic_pol_directions/after_cand_comment_directions.json', after_cand_comment_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "bf3c7e5a-1854-4dd9-b226-e351f33b9a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get average, min, max, and dominant sentiment for each state\n",
    "def get_direction_stats(all_directions):\n",
    "    stats = all_directions.copy()\n",
    "    \n",
    "    for k in stats.keys():\n",
    "        state_dir = stats[k].copy()\n",
    "        \n",
    "        for d in state_dir.keys():\n",
    "            avgs = dict()\n",
    "            topics = state_dir[d].copy()\n",
    "\n",
    "            for t in topics.keys():\n",
    "                topic = topics[t].copy()\n",
    "                if 'scores' not in topic.keys():\n",
    "                    topic['scores'] = [0]\n",
    "                    \n",
    "                topic['min'] = min(topic['scores'])\n",
    "                topic['max'] = max(topic['scores'])\n",
    "                topic['average'] = np.mean(topic['scores'])\n",
    "                avgs[topic['average']] = t\n",
    "                \n",
    "                if 'num_posts' not in topic.keys():\n",
    "                    topic['num_posts'] = 0\n",
    "                topics[t] = topic\n",
    "            \n",
    "            if len(avgs.keys()) > 0:\n",
    "                avg_score = max(avgs.keys())\n",
    "                direction = avgs[avg_score]\n",
    "                topics['avg_score'] = avg_score\n",
    "                topics['direction'] = direction\n",
    "                state_dir[d] = topics\n",
    "        stats[k] = state_dir\n",
    "    return stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "9c09779a-b536-4be0-add8-500aea8d88a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "after_topic_post_stats = get_direction_stats(after_cand_post_dir)\n",
    "after_topic_comment_stats = get_direction_stats(after_cand_comment_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "48fa8054-fd2a-48bf-a305-55080ede2d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_data('data/topic_pol_directions/after_topic_post_stats.json', after_topic_post_stats)\n",
    "save_data('data/topic_pol_directions/after_topic_comment_stats.json', after_topic_comment_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de83c5fe-c466-4c19-b0da-6f8517b01634",
   "metadata": {},
   "source": [
    "# ===== OLD STUFF ===== DO NOT RUN ====="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9749591-6ad0-4a38-8771-ba75754b52e7",
   "metadata": {},
   "source": [
    "## Option 1: take sentiment of entire post, give an average rating\n",
    "\n",
    "Get the aggregated sentiment score for each post. Might want something like:\n",
    "```all_sentiments = {\n",
    "    'texas': {\n",
    "        'positive': {\n",
    "           'scores': [0, 0, ...],\n",
    "           'average': 0.0,\n",
    "           'max': 0.0,\n",
    "           'min': 0.0,\n",
    "           'num_posts': 0\n",
    "       },\n",
    "       'neutral': {\n",
    "           'scores': [0, 0, ...],\n",
    "           'average': 0.0,\n",
    "           'max': 0.0,\n",
    "           'min': 0.0,\n",
    "           'num_posts': 0\n",
    "       }\n",
    "       'negative': {\n",
    "           'scores': [0, 0, ...],\n",
    "           'average': 0.0,\n",
    "           'max': 0.0,\n",
    "           'min': 0.0,\n",
    "           'num_posts': 0\n",
    "       },\n",
    "       'sentiment': 'positive',\n",
    "       'avg_sentiment': 0.0\n",
    "    },\n",
    "    ...\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01b8f7ae-470c-4c8c-b6c8-af7d62a10493",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper for creating the json above\n",
    "def record_sentiment(sent_data, score):\n",
    "    if \"scores\" in sent_data.keys():\n",
    "        sent_data[\"scores\"].append(score)\n",
    "    else:\n",
    "        sent_data[\"scores\"] = [score]\n",
    "\n",
    "    if \"num_posts\" in sent_data.keys():\n",
    "        sent_data[\"num_posts\"] += 1\n",
    "    else:\n",
    "        sent_data[\"num_posts\"] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "174ecf5a-cf72-47e9-980c-c1f3b3d9ed82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterate through each state and compute highest weight sentiment for each post\n",
    "def get_sentiment_scores_posts(political_posts):\n",
    "    all_sentiment = dict()\n",
    "    \n",
    "    for k in political_posts.keys():\n",
    "        state_data = {\n",
    "            'positive': {},\n",
    "            'neutral': {},\n",
    "            'negative': {},\n",
    "        }\n",
    "        \n",
    "        for post in political_posts[k]:\n",
    "            # as we are not working with semantic meaning, we will combine the text and titles of the posts\n",
    "            content = post['title'] + \" \" + post['selftext']\n",
    "            label, score = get_sentiment_label_score(content)\n",
    "            record_sentiment(state_data[label], score)\n",
    "            \n",
    "            all_sentiment[k] = state_data\n",
    "    return all_sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40510529-b0ab-4118-87f8-6df57ffc9b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is the comments version of the above\n",
    "def get_sentiment_scores_comments(political_comments):\n",
    "    all_sentiment = dict()\n",
    "    \n",
    "    for k in political_comments.keys():\n",
    "        state_data = {\n",
    "            'positive': {},\n",
    "            'neutral': {},\n",
    "            'negative': {},\n",
    "        }\n",
    "        \n",
    "        for post in political_comments[k]:\n",
    "            content = post['body']\n",
    "            label, score = get_sentiment_label_score(content)\n",
    "            record_sentiment(state_data[label], score)\n",
    "            \n",
    "            all_sentiment[k] = state_data\n",
    "    return all_sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb23aec-2954-4bb7-ae38-fd93036dea4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#after_post_sentiments = get_sentiment_scores_posts(after_political_posts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f36fca-aba2-4ec0-bb1e-33f39ad07e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#before_post_sentiments = get_sentiment_scores_posts(before_political_posts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "000139b2-7746-4b8b-8427-822bb589ffb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#after_comment_sentiments = get_sentiment_scores_comments(after_political_comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f97a02bc-95e8-4506-9e01-0730f5f944df",
   "metadata": {},
   "outputs": [],
   "source": [
    "#before_comment_sentiments = get_sentiment_scores_comments(before_political_comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "216e15ad-3803-4cd8-8608-9bdc0790cdb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# after_post_sentiments = extract_data('reddit-sentiment-analysis/sentiments/all_posts/after_post_sentiments.json')\n",
    "# before_post_sentiments = extract_data('reddit-sentiment-analysis/sentiments/all_posts/before_post_sentiments.json')\n",
    "# after_comment_sentiments = extract_data('reddit-sentiment-analysis/sentiments/all_posts/after_comments_sentiments.json')\n",
    "# before_comment_sentiments = extract_data('reddit-sentiment-analysis/sentiments/all_posts/before_comments_sentiments.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85661625-1f1a-4c86-848e-2b36d9ed0cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get average, min, max, and dominant sentiment for each state\n",
    "def get_sentiment_stats(all_sentiment):\n",
    "    stats = dict()\n",
    "    for k in all_sentiment.keys():\n",
    "        avgs = dict()\n",
    "        stats[k] = dict()\n",
    "        state_sent = all_sentiment[k]\n",
    "        \n",
    "        for s in state_sent.keys():\n",
    "            sent = state_sent[s]\n",
    "            if 'scores' not in sent.keys():\n",
    "                sent['scores'] = [0]\n",
    "                \n",
    "            sent['min'] = min(sent['scores'])\n",
    "            sent['max'] = max(sent['scores'])\n",
    "            sent['average'] = np.mean(sent['scores'])\n",
    "            avgs[sent['average']] = s\n",
    "            \n",
    "            if 'num_posts' not in sent.keys():\n",
    "                sent['num_posts'] = 0\n",
    "    \n",
    "        avg_sentiment = max(avgs.keys())\n",
    "        sentiment = avgs[avg_sentiment]\n",
    "        stats[k]['avg_sentiment'] = avg_sentiment\n",
    "        stats[k]['sentiment'] = sentiment\n",
    "    return stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48a31f26-a4ee-4979-ae5c-3478c92ff56d",
   "metadata": {},
   "outputs": [],
   "source": [
    "after_post_sentiments_stats = get_sentiment_stats(after_post_sentiments)\n",
    "before_post_sentiments_stats = get_sentiment_stats(before_post_sentiments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dd6132e-4d5d-4d6a-b7bd-43ed597f27e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "after_comment_sentiments_stats = get_sentiment_stats(after_comment_sentiments)\n",
    "before_comment_sentiments_stats = get_sentiment_stats(before_comment_sentiments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2d4b987-adc0-4bf3-a9aa-21fede2de744",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_data('after_post_sentiments.json', after_post_sentiments)\n",
    "save_data('before_post_sentiments.json', before_post_sentiments)\n",
    "save_data('after_comment_sentiments.json', after_comment_sentiments)\n",
    "save_data('before_comment_sentiments.json', before_comment_sentiments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98014391-d80e-45d3-a7aa-aded9d1cdfc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_data('after_post_stats.json', after_post_sentiments_stats)\n",
    "save_data('before_post_stats.json', before_post_sentiments_stats)\n",
    "save_data('after_comment_stats.json', after_comment_sentiments_stats)\n",
    "save_data('before_comment_stats.json', before_comment_sentiments_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e814244a-6a14-44aa-a25b-5e178a740d9a",
   "metadata": {},
   "source": [
    "## Option 2: Get sentiment for each topic per state, print the same statistics as above\n",
    "Further subdivide the political posts by their main topics. Data will look something like this:\n",
    "```all_sentiments = {\n",
    "    'texas': {\n",
    "        'election': {\n",
    "            'positive': {\n",
    "                   'scores': [0, 0, ...],\n",
    "                   'average': 0.0,\n",
    "                   'max': 0.0,\n",
    "                   'min': 0.0,\n",
    "                   'num_posts': 0\n",
    "               },\n",
    "               'neutral': {\n",
    "                   'scores': [0, 0, ...],\n",
    "                   'average': 0.0,\n",
    "                   'max': 0.0,\n",
    "                   'min': 0.0,\n",
    "                   'num_posts': 0\n",
    "               }\n",
    "               'negative': {\n",
    "                   'scores': [0, 0, ...],\n",
    "                   'average': 0.0,\n",
    "                   'max': 0.0,\n",
    "                   'min': 0.0,\n",
    "                   'num_posts': 0\n",
    "               },\n",
    "               'sentiment': 'positive',\n",
    "               'avg_sentiment': 0.0\n",
    "            },\n",
    "        },\n",
    "        'republican': {\n",
    "            'positive': {\n",
    "                ...\n",
    "               },\n",
    "               'neutral': {\n",
    "                ...\n",
    "               }\n",
    "               'negative': {\n",
    "                ...\n",
    "               },\n",
    "               'sentiment': 'positive',\n",
    "               'avg_sentiment': 0.0\n",
    "            },\n",
    "        },\n",
    "        ...\n",
    "    },\n",
    "    ...\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03c59abb-42bb-47c2-b2e1-cdd7861286a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# group filtered political posts \n",
    "def group_political_posts(posts):\n",
    "    grouped_posts = dict()\n",
    "        \n",
    "    for k in posts.keys():\n",
    "        grouped_posts[k] = dict()\n",
    "        state_posts = posts[k]\n",
    "\n",
    "        for post in state_posts:\n",
    "            for topic in topics_dict.keys():\n",
    "                post_set = set()\n",
    "                \n",
    "                for word in topics_dict[topic]:\n",
    "                    if word in post[\"selftext\"].lower() or word in post[\"title\"].lower():\n",
    "                        post_set.add(post[\"selftext\"] + \" \" + post[\"title\"])\n",
    "                grouped_posts[k][topic] = list(post_set)\n",
    "    return grouped_posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "282bfd75-2b0b-4711-8198-9ae706a8895c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# group filtered political comments \n",
    "def group_political_comments(comments):\n",
    "    grouped_comments = dict()\n",
    "        \n",
    "    for k in comments.keys():\n",
    "        grouped_comments[k] = dict()\n",
    "        state_comments = comments[k]\n",
    "\n",
    "        for comment in state_comments:\n",
    "            for topic in topics_dict.keys():\n",
    "                comment_set = set()\n",
    "                \n",
    "                for word in topics_dict[topic]:\n",
    "                    if word in comment[\"body\"].lower():\n",
    "                        comment_set.add(comment[\"body\"])\n",
    "                grouped_comments[k][topic] = list(comment_set)\n",
    "    return grouped_comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e69e6a0e-4ec5-475a-91e4-8ad4fca57972",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_posts_after = group_political_posts(after_political_posts)\n",
    "grouped_posts_before = group_political_posts(before_political_posts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4513714e-d6b5-43f5-8e16-c6e911d6b721",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_posts_after['michigan']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2a051af-fbb6-44c7-bde0-5770c5cddb8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_comments_after = group_political_comments(after_political_comments)\n",
    "grouped_comments_before = group_political_comments(before_political_comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c31e0c2-4523-498b-b3bf-65a83328b882",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_comments_after['nevada']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea1c59a-aad5-4afe-8d60-ce1697a1b312",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print out size of grouped posts per state - for testing\n",
    "def count_grouped_posts(grouped_posts):\n",
    "    group_posts_size = dict()\n",
    "    for k in grouped_posts.keys():\n",
    "        group_posts_size[k] = dict()\n",
    "        \n",
    "        for t in grouped_posts[k].keys(): \n",
    "            group_posts_size[k][t] = len(grouped_posts[k][t])\n",
    "    return group_posts_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5277da98-39ce-4cd8-9bf4-e675836be5e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#count_grouped_posts(grouped_posts_after)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65f21e88-a97c-4961-91fe-8c1ce7c3b1c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#count_grouped_posts(grouped_posts_before)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be3eac7d-01a1-4503-935d-8a07f699ce2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#count_grouped_posts(grouped_comments_after)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8de60371-041c-41bd-8b3b-b791c2d51dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#count_grouped_posts(grouped_comments_before)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaddb5a2-537f-4397-8770-3f5e15a203f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentiment_scores_grouped_posts(grouped_posts):\n",
    "    all_sentiment = dict()\n",
    "    \n",
    "    for k in grouped_posts.keys():\n",
    "        all_sentiment[k] = dict()\n",
    "        \n",
    "        for topic in grouped_posts[k].keys():\n",
    "            all_sentiment[k][topic] = dict()\n",
    "            topic_data = {\n",
    "                'positive': {},\n",
    "                'neutral': {},\n",
    "                'negative': {},\n",
    "            }\n",
    "\n",
    "            for post in grouped_posts[k][topic]:\n",
    "                label, score = get_sentiment_label_score(post)\n",
    "                record_sentiment(topic_data[label], score)\n",
    "                \n",
    "                all_sentiment[k][topic] = topic_data\n",
    "    return all_sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38b883ee-a4d9-4034-ac79-af5ffd297925",
   "metadata": {},
   "outputs": [],
   "source": [
    "post_sentiment_per_topic_after = get_sentiment_scores_grouped_posts(grouped_posts_after)\n",
    "post_sentiment_per_topic_before = get_sentiment_scores_grouped_posts(grouped_posts_before)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccb9f57f-17f6-426d-ae63-8cae73f6e64a",
   "metadata": {},
   "outputs": [],
   "source": [
    "comment_sentiment_per_topic_after = get_sentiment_scores_grouped_posts(grouped_comments_after)\n",
    "comment_sentiment_per_topic_before = get_sentiment_scores_grouped_posts(grouped_comments_before)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b01229f-f2e8-4bbd-87f7-91dd74c75175",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get average, min, max, and dominant sentiment for each topic per state\n",
    "def get_sentiment_stats(all_sentiment):\n",
    "    stats = dict()\n",
    "    for k in all_sentiment.keys():\n",
    "        stats[k] = dict()\n",
    "        \n",
    "        for topic in all_sentiment[k].keys():\n",
    "            stats[k][topic] = dict()\n",
    "            topic_sent = all_sentiment[k][topic]\n",
    "            avgs = dict()\n",
    "        \n",
    "            for s in topic_sent.keys():\n",
    "                sent = topic_sent[s]\n",
    "                if 'scores' not in sent.keys():\n",
    "                    sent['scores'] = [0]\n",
    "                    \n",
    "                sent['min'] = min(sent['scores'])\n",
    "                sent['max'] = max(sent['scores'])\n",
    "                sent['average'] = np.mean(sent['scores'])\n",
    "                avgs[sent['average']] = s\n",
    "                \n",
    "                if 'num_posts' not in sent.keys():\n",
    "                    sent['num_posts'] = 0\n",
    "        \n",
    "            if len(avgs.keys()) > 0:\n",
    "                avg_sentiment = max(avgs.keys())\n",
    "                sentiment = avgs[avg_sentiment]\n",
    "                stats[k][topic]['avg_sentiment'] = avg_sentiment\n",
    "                stats[k][topic]['sentiment'] = sentiment\n",
    "    return stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f46b8f8-636c-44ce-9022-dd74816b9919",
   "metadata": {},
   "outputs": [],
   "source": [
    "post_stats_per_topic_after = get_sentiment_stats(post_sentiment_per_topic_after)\n",
    "post_stats_per_topic_before = get_sentiment_stats(post_sentiment_per_topic_before)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7141f904-34c0-4fb0-928c-4fcbac3cece7",
   "metadata": {},
   "outputs": [],
   "source": [
    "comment_stats_per_topic_after = get_sentiment_stats(comment_sentiment_per_topic_after)\n",
    "comment_stats_per_topic_before = get_sentiment_stats(comment_sentiment_per_topic_before)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f391d76-3686-4999-85f4-af3ffc062fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_data('after_post_sentiments_per_topic.json', post_sentiment_per_topic_after)\n",
    "save_data('before_post_sentiments_per_topic.json', post_sentiment_per_topic_before)\n",
    "save_data('after_comment_sentiments_per_topic.json', comment_sentiment_per_topic_after)\n",
    "save_data('before_comment_sentiments_per_topic.json', comment_sentiment_per_topic_before)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e705f1cd-9c88-4aca-b89b-b17ab3185c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_data('after_post_stats_per_topic.json', post_stats_per_topic_after)\n",
    "save_data('before_post_stats_per_topic.json', post_stats_per_topic_before)\n",
    "save_data('after_comment_stats_per_topic.json', comment_stats_per_topic_after)\n",
    "save_data('before_comment_stats_per_topic.json', comment_stats_per_topic_before)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c95892e5-8ec8-41e0-983b-8e5eed4b27a5",
   "metadata": {},
   "source": [
    "## Testing Topic Modeling for Political Data Extraction\n",
    "Probably don't run the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94c0da96-ae4c-4f9e-ae3f-cd741e896545",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bertopic import BERTopic\n",
    "topic_model = BERTopic.load(\"MaartenGr/BERTopic_Wikipedia\")\n",
    "\n",
    "model_topics = topic_model.get_topic_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c6ca2b2-d388-476e-99fe-25ec5b81a56e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6c096c9-b78b-4c30-b90d-d5c6ebf33754",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taking the numbers of topics that contain our list of keywords\n",
    "political_topic_nums = []\n",
    "for w in keywords:\n",
    "    for i in range(len(model_topics[\"Representation\"])):\n",
    "        if w in model_topics[\"Representation\"][i]:\n",
    "            political_topic_nums.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebfeefa1-e7dc-468c-81a7-cd21d5ea8c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "political_topic_nums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa483c04-b1ac-4d55-a0f3-757863ca7c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Document needs to be a list to pass into topic modelling model\n",
    "# Create a new json of { state1: [ \"title1, text1\", \"title2, text2\", ... ], state2: [\"title1, text1\", ...]\n",
    "state_to_post = dict()\n",
    "\n",
    "for k in political_posts.keys():\n",
    "    posts = []\n",
    "    for post in political_posts[k]:\n",
    "        post_str = post['title'] + \" \" + post['selftext']\n",
    "        posts.append(post_str)\n",
    "    state_to_post[k] = posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3000e581-89c5-4b89-a6cc-f77d37d885b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_to_topic = dict()\n",
    "\n",
    "for k in state_to_post.keys():\n",
    "    if len(state_to_post[k]) != 0:\n",
    "        post_topics, post_probs = topic_model.transform(state_to_post[k])\n",
    "        state_to_topic[k] = {\n",
    "            'topics': post_topics,\n",
    "            'probabilities': post_probs\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37d1577c-6db1-4e66-a2a5-a050d51fb410",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_to_topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9896b2cb-4d9e-4677-9bf5-ac050ab52463",
   "metadata": {},
   "outputs": [],
   "source": [
    "political_posts_modeled = dict()\n",
    "\n",
    "for k in state_to_topic.keys():\n",
    "    indices = []\n",
    "    state = state_to_topic[k]\n",
    "    state_topics = state['topics']\n",
    "    state_probs = state['probabilities']\n",
    "\n",
    "    for i in range(len(state_topics)):\n",
    "        if state_topics[i] in political_topic_nums and state_probs[i] >= 0.5:\n",
    "            indices.append(i)\n",
    "    political_posts_modeled[k] = indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb18932-1d32-4fa6-8ca2-40663678114f",
   "metadata": {},
   "outputs": [],
   "source": [
    "political_posts_modeled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4652d47-cc23-4cda-b983-d1c9b359d452",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
