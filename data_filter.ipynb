{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e2a68b94-0901-4e94-9a99-38f9c5e10bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "740b3445-ba8f-48fb-88b3-53e6bc2194b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit_dict = dict()\n",
    "\n",
    "with open('state_reddit_data.json') as f:\n",
    "    reddit_dict = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f898e6b5-88d1-4eee-9e9f-e1646381e450",
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterate through dict and only get the posts and comments\n",
    "data = dict()\n",
    "\n",
    "for k in reddit_dict.keys():\n",
    "    state_posts = []\n",
    "    state_comments = []\n",
    "    \n",
    "    for p in reddit_dict[k]:\n",
    "        post = {\n",
    "            \"selftext\": p[\"selftext\"],\n",
    "            \"title\": p[\"title\"],\n",
    "            \"comments\": [c[\"body\"] for c in p[\"comments\"]]\n",
    "        }\n",
    "        state_posts.append(post)\n",
    "    data[k] = state_posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "327ad669-a2d9-4f79-8626-bfb6747649c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of words to look for when filtering political posts\n",
    "keywords = [\n",
    "    \"election\",\n",
    "    \"president\",\n",
    "    \"presidential\",\n",
    "    \"democrat\",\n",
    "    \"republican\",\n",
    "    \"vote \",\n",
    "    \"voting\",\n",
    "    \"donald\",\n",
    "    \"trump\",\n",
    "    \"donald trump\",\n",
    "    \"kamala\",\n",
    "    \"harris\",\n",
    "    \"kamala harris\",\n",
    "    \"abortion\",\n",
    "    \"democracy\",\n",
    "    \"immigration\",\n",
    "    \"economy\",\n",
    "    \"war \",\n",
    "    \"ukraine\",\n",
    "    \"israel\",\n",
    "    \"palestine\",\n",
    "    \"climate\",\n",
    "    \"healthcare\",\n",
    "    \"inflation\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1fdb8311-f9e8-4ec2-9389-cb1e1ae5472a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter for political posts\n",
    "political_posts = dict()\n",
    "\n",
    "for k in data.keys():\n",
    "    posts = []\n",
    "\n",
    "    for post in data[k]:\n",
    "        for w in keywords:\n",
    "            if w in post[\"selftext\"].lower() or w in post[\"title\"].lower():\n",
    "                posts.append(post)\n",
    "\n",
    "    political_posts[k] = posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "051772ac-16e1-4fe7-87ea-4e9ddf163f41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'texas': 8,\n",
       " 'california': 14,\n",
       " 'newjersey': 0,\n",
       " 'michigan': 5,\n",
       " 'minnesota': 3,\n",
       " 'colorado': 1,\n",
       " 'wisconsin': 17,\n",
       " 'florida': 5,\n",
       " 'connecticut': 7,\n",
       " 'oregon': 1,\n",
       " 'ohio': 4,\n",
       " 'hawaii': 0,\n",
       " 'northcarolina': 16,\n",
       " 'oklahoma': 11,\n",
       " 'maryland': 3,\n",
       " 'arizona': 3,\n",
       " 'virginia': 15,\n",
       " 'maine': 10,\n",
       " 'indiana': 4,\n",
       " 'iowa': 11,\n",
       " 'washington': 10,\n",
       " 'newhampshire': 3,\n",
       " 'alaska': 9,\n",
       " 'louisiana': 3,\n",
       " 'massachusetts': 3,\n",
       " 'vermont': 2,\n",
       " 'newyork': 19,\n",
       " 'arkansas': 5,\n",
       " 'pennsylvania': 10,\n",
       " 'alabama': 2,\n",
       " 'kentucky': 6,\n",
       " 'southcarolina': 1,\n",
       " 'georgia': 7,\n",
       " 'montana': 0,\n",
       " 'delaware': 2,\n",
       " 'utah': 6,\n",
       " 'rhodeisland': 1,\n",
       " 'missouri': 12,\n",
       " 'tennessee': 10,\n",
       " 'nebraska': 12,\n",
       " 'illinois': 15,\n",
       " 'westvirginia': 3,\n",
       " 'newmexico': 7,\n",
       " 'mississippi': 12,\n",
       " 'kansas': 13,\n",
       " 'northdakota': 11,\n",
       " 'idaho': 9,\n",
       " 'southdakota': 44,\n",
       " 'wyoming': 6,\n",
       " 'nevada': 8}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "just_posts_size = dict()\n",
    "for k in data.keys():\n",
    "    just_posts_size[k] = len(political_posts[k])\n",
    "just_posts_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "73a9a598-1c0c-4d8f-a46e-b9df40c8cdc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter for political comments in addition\n",
    "political_data = dict()\n",
    "\n",
    "for k in data.keys():\n",
    "    posts_and_comments = []\n",
    "\n",
    "    for post in data[k]:\n",
    "        for w in keywords:\n",
    "            if w in post[\"selftext\"].lower() or w in post[\"title\"].lower():\n",
    "                posts_and_comments.append(post)\n",
    "            elif w in \" \".join(post[\"comments\"]).lower():\n",
    "                posts_and_comments.append(post)\n",
    "\n",
    "    political_data[k] = posts_and_comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fd5bbf7d-cee7-4b5e-8178-303434cf2f7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'texas': 171,\n",
       " 'california': 70,\n",
       " 'newjersey': 17,\n",
       " 'michigan': 64,\n",
       " 'minnesota': 68,\n",
       " 'colorado': 55,\n",
       " 'wisconsin': 88,\n",
       " 'florida': 61,\n",
       " 'connecticut': 41,\n",
       " 'oregon': 78,\n",
       " 'ohio': 105,\n",
       " 'hawaii': 23,\n",
       " 'northcarolina': 100,\n",
       " 'oklahoma': 151,\n",
       " 'maryland': 95,\n",
       " 'arizona': 38,\n",
       " 'virginia': 92,\n",
       " 'maine': 123,\n",
       " 'indiana': 109,\n",
       " 'iowa': 144,\n",
       " 'washington': 49,\n",
       " 'newhampshire': 37,\n",
       " 'alaska': 144,\n",
       " 'louisiana': 79,\n",
       " 'massachusetts': 62,\n",
       " 'vermont': 38,\n",
       " 'newyork': 175,\n",
       " 'arkansas': 79,\n",
       " 'pennsylvania': 152,\n",
       " 'alabama': 124,\n",
       " 'kentucky': 58,\n",
       " 'southcarolina': 68,\n",
       " 'georgia': 65,\n",
       " 'montana': 13,\n",
       " 'delaware': 57,\n",
       " 'utah': 66,\n",
       " 'rhodeisland': 15,\n",
       " 'missouri': 122,\n",
       " 'tennessee': 96,\n",
       " 'nebraska': 126,\n",
       " 'illinois': 162,\n",
       " 'westvirginia': 77,\n",
       " 'newmexico': 38,\n",
       " 'mississippi': 100,\n",
       " 'kansas': 79,\n",
       " 'northdakota': 86,\n",
       " 'idaho': 132,\n",
       " 'southdakota': 247,\n",
       " 'wyoming': 55,\n",
       " 'nevada': 111}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posts_and_comments_size = dict()\n",
    "for k in data.keys():\n",
    "    posts_and_comments_size[k] = len(political_data[k])\n",
    "posts_and_comments_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ebd16831-f088-463d-b240-8fb9370bd108",
   "metadata": {},
   "outputs": [],
   "source": [
    "political_comments = dict()\n",
    "\n",
    "for k in political_data.keys():\n",
    "    filtered_comments = []\n",
    "    for state in political_data[k]:\n",
    "        for c in state[\"comments\"]:\n",
    "               for w in keywords:\n",
    "                   if w in c:\n",
    "                       filtered_comments.append(c)\n",
    "    political_comments[k] = filtered_comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "24a0f65a-a15d-4101-8b6e-8ad2439213de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'texas': 3419,\n",
       " 'california': 2072,\n",
       " 'newjersey': 36,\n",
       " 'michigan': 1163,\n",
       " 'minnesota': 833,\n",
       " 'colorado': 1198,\n",
       " 'wisconsin': 1194,\n",
       " 'florida': 521,\n",
       " 'connecticut': 380,\n",
       " 'oregon': 1414,\n",
       " 'ohio': 2308,\n",
       " 'hawaii': 50,\n",
       " 'northcarolina': 3866,\n",
       " 'oklahoma': 1194,\n",
       " 'maryland': 2697,\n",
       " 'arizona': 300,\n",
       " 'virginia': 2719,\n",
       " 'maine': 4302,\n",
       " 'indiana': 3341,\n",
       " 'iowa': 5392,\n",
       " 'washington': 841,\n",
       " 'newhampshire': 208,\n",
       " 'alaska': 6842,\n",
       " 'louisiana': 452,\n",
       " 'massachusetts': 1311,\n",
       " 'vermont': 162,\n",
       " 'newyork': 9817,\n",
       " 'arkansas': 951,\n",
       " 'pennsylvania': 9018,\n",
       " 'alabama': 2374,\n",
       " 'kentucky': 640,\n",
       " 'southcarolina': 1764,\n",
       " 'georgia': 690,\n",
       " 'montana': 34,\n",
       " 'delaware': 674,\n",
       " 'utah': 989,\n",
       " 'rhodeisland': 41,\n",
       " 'missouri': 2401,\n",
       " 'tennessee': 1798,\n",
       " 'nebraska': 2826,\n",
       " 'illinois': 9529,\n",
       " 'westvirginia': 1422,\n",
       " 'newmexico': 511,\n",
       " 'mississippi': 2646,\n",
       " 'kansas': 1445,\n",
       " 'northdakota': 3291,\n",
       " 'idaho': 2106,\n",
       " 'southdakota': 6655,\n",
       " 'wyoming': 790,\n",
       " 'nevada': 10842}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments_size = dict()\n",
    "for k in political_comments.keys():\n",
    "    comments_size[k] = len(political_comments[k])\n",
    "comments_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "42ecbf37-cfaf-4dd8-a2e5-6b4e685ad14b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA FORMAT\n",
    "# political_data contains posts and comments of results when filtered for either political posts or comments\n",
    "\n",
    "# political_data = {\n",
    "#    'texas': [\n",
    "#        {\n",
    "#            'selftext': \"__\",\n",
    "#            'title': \"__\",\n",
    "#            'comments': [\"__\", \"__\", \"__\"]\n",
    "#        },\n",
    "#        {\n",
    "#            'selftext': \"__\",\n",
    "#            'title': \"__\",\n",
    "#            'comments': [\"__\", \"__\", \"__\"]\n",
    "#        },\n",
    "#        ...\n",
    "#    ],\n",
    "#    'california': [\n",
    "#        {\n",
    "#            'selftext': \"__\",\n",
    "#            'title': \"__\",\n",
    "#            'comments': [\"__\", \"__\", \"__\"]\n",
    "#        },\n",
    "#        ...\n",
    "#    ]\n",
    "# }\n",
    "\n",
    "# political_posts contains posts that contain any of the defined political keywords\n",
    "# data should look the same as above\n",
    "\n",
    "# political_comments contains state names mapped to comments that contain any of the defined political keywords\n",
    "# political_comments = {\n",
    "#    'texas': [__, __, __],\n",
    "#    'california': [__, __, __],\n",
    "#    ...\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ff077ff7-79a8-4681-9b0a-cb735a3af526",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sentiment analysis\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "from transformers import TFAutoModelForSequenceClassification\n",
    "from transformers import AutoTokenizer, AutoConfig\n",
    "import numpy as np\n",
    "from scipy.special import softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f8fafc40-1503-4031-afe8-d3e271c9c7b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = \"cardiffnlp/twitter-roberta-base-sentiment-latest\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
    "config = AutoConfig.from_pretrained(MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0bd4650f-9c5e-433d-b03f-873881a2a663",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-24 00:02:26.537803: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "Some weights of the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment-latest were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "49c162ce-7ec9-4ecb-aef7-19846892f7de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 1 0]\n",
      "{0: 'negative', 1: 'neutral', 2: 'positive'}\n",
      "1) positive 0.9749\n",
      "2) neutral 0.0208\n",
      "3) negative 0.0043\n"
     ]
    }
   ],
   "source": [
    "## TEST - must use PyTorch version, the tensorflow one is not as accurate\n",
    "text = \"I love you!\"\n",
    "encoded_input = tokenizer(text, return_tensors='pt')\n",
    "output = model(**encoded_input)\n",
    "\n",
    "scores = output[0][0].detach().numpy()\n",
    "scores = softmax(scores)\n",
    "\n",
    "ranking = np.argsort(scores)\n",
    "ranking = ranking[::-1]\n",
    "print(ranking)\n",
    "print(config.id2label)\n",
    "\n",
    "for i in range(scores.shape[0]):\n",
    "    l = config.id2label[ranking[i]]\n",
    "    s = scores[ranking[i]]\n",
    "    print(f\"{i+1}) {l} {np.round(float(s), 4)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9e0fb060-1896-49d3-8c73-2b45c51b8313",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentiment_label_score(text):\n",
    "    # get output from model\n",
    "    encoded_input = tokenizer(text, return_tensors='pt', max_length=512, truncation=True)\n",
    "    output = model(**encoded_input)\n",
    "\n",
    "    # compute softmax scores\n",
    "    scores = output[0][0].detach().numpy()\n",
    "    scores = softmax(scores)\n",
    "\n",
    "    # ranking = list of labels in decreasing order of sentiment score\n",
    "    ranking = np.argsort(scores)[::-1]\n",
    "\n",
    "    # return dictionary of {ranking: score} for given text\n",
    "    # sentiment_map = dict()\n",
    "    # for i in range(scores.shape[0]):\n",
    "    #     l = config.id2label[ranking[i]]\n",
    "    #     s = scores[ranking[i]]\n",
    "    #     sentiment_map[l] = s\n",
    "\n",
    "    # return largest score and the associated sentiment\n",
    "    l = config.id2label[ranking[0]]\n",
    "    s = scores[ranking[0]]\n",
    "    return l, s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "01b8f7ae-470c-4c8c-b6c8-af7d62a10493",
   "metadata": {},
   "outputs": [],
   "source": [
    "def record_sentiment(sent_data, score, key):\n",
    "    if \"scores\" in sent_data.keys():\n",
    "        sent_data[\"scores\"].append(score)\n",
    "    else:\n",
    "        sent_data[\"scores\"] = [score]\n",
    "\n",
    "    if f\"num_{key}\" in sent_data.keys():\n",
    "        sent_data[f\"num_{key}\"] += 1\n",
    "    else:\n",
    "        sent_data[f\"num_{key}\"] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "174ecf5a-cf72-47e9-980c-c1f3b3d9ed82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 1: take sentiment of entire post, give an average rating\n",
    "\n",
    "# Get the aggregated sentiment score for each post. Might want something like:\n",
    "# all_sentiments = {\n",
    "#    'texas': {\n",
    "#         'positive': {\n",
    "#            'scores': [0, 0, ...],\n",
    "#            'average': 0.0,\n",
    "#            'max': 0.0,\n",
    "#            'min': 0.0,\n",
    "#            'num_selftext': 0,\n",
    "#            'num_title': 0\n",
    "#        },\n",
    "#        'neutral': {\n",
    "#            ...\n",
    "#        }\n",
    "#        'negative': {\n",
    "#            ...\n",
    "#        },\n",
    "#        'sentiment': 'positive'\n",
    "#     }, ...}\n",
    "\n",
    "# iterate through each state and compute highest weight sentiment for each post\n",
    "all_sentiment = dict()\n",
    "\n",
    "for k in political_posts.keys():\n",
    "    state_data = {\n",
    "        'positive': {},\n",
    "        'neutral': {},\n",
    "        'negative': {},\n",
    "    }\n",
    "    \n",
    "    for post in political_posts[k]:\n",
    "        label, score = get_sentiment_label_score(post['selftext'])\n",
    "        record_sentiment(state_data[label], score, 'selftext')\n",
    "    \n",
    "        label, score = get_sentiment_label_score(post['title'])\n",
    "        record_sentiment(state_data[label], score, 'title')\n",
    "        \n",
    "        all_sentiment[k] = state_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e28641a9-59ef-48c5-bf91-62aec75e6d35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'positive': {'scores': [0.4012986, 0.4012986, 0.4012986], 'num_selftext': 3},\n",
       " 'neutral': {'scores': [0.61926496,\n",
       "   0.61926496,\n",
       "   0.81732804,\n",
       "   0.7474167,\n",
       "   0.6769628],\n",
       "  'num_title': 3,\n",
       "  'num_selftext': 2},\n",
       " 'negative': {'scores': [0.5218421, 0.6263394], 'num_title': 2}}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_sentiment['michigan']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "85661625-1f1a-4c86-848e-2b36d9ed0cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get average, min, max, and dominant sentiment for each state\n",
    "for k in all_sentiment.keys():\n",
    "    avgs = dict()\n",
    "    state_sent = all_sentiment[k]\n",
    "    \n",
    "    for s in state_sent.keys():\n",
    "        sent = state_sent[s]\n",
    "        if 'scores' not in sent.keys():\n",
    "            sent['scores'] = [0]\n",
    "            \n",
    "        sent['min'] = min(sent['scores'])\n",
    "        sent['max'] = max(sent['scores'])\n",
    "        sent['average'] = np.mean(sent['scores'])\n",
    "        avgs[sent['average']] = s\n",
    "        \n",
    "        if 'num_selftext' not in sent.keys():\n",
    "            sent['num_selftext'] = 0\n",
    "        if 'num_title' not in sent.keys():\n",
    "            sent['num_title'] = 0\n",
    "\n",
    "    avg_sentiment = max(avgs.keys())\n",
    "    sentiment = avgs[avg_sentiment]\n",
    "    all_sentiment[k]['avg_sentiment'] = avg_sentiment\n",
    "    all_sentiment[k]['sentiment'] = sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fe37231-d545-4e72-93b6-c51dea433d08",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
